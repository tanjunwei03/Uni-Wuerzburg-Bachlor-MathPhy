\documentclass[prb,12pt]{revtex4-2}

\usepackage{amsmath, amssymb,physics,amsfonts,amsthm}
\usepackage{enumitem}
\usepackage[most]{tcolorbox}
\usepackage{cancel}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{xurl}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage[normalem]{ulem}
\usepackage{transparent}
\usepackage{float}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{thmtools}
\usepackage{thm-restate}
\usepackage[framemethod=TikZ]{mdframed}
\mdfsetup{skipabove=1em,skipbelow=0em, innertopmargin=12pt, innerbottommargin=8pt}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, mdframed={  } ]{thmbox}
%put nobreak in mdframed
\declaretheorem[style=thmbox, name=Theorem]{Theorem}
\declaretheorem[sibling=Theorem, style=thmbox, name=Definition]{Definition}
\declaretheorem[sibling=Theorem, style=thmbox, name=Corollary]{Corollary}
\declaretheorem[sibling=Theorem, style=thmbox, name=Example]{Example}
\declaretheorem[sibling=Theorem, style=thmbox, name=Proposition]{Proposition}
\declaretheorem[sibling=Theorem, style=thmbox, name=Lemma]{Lemma}
%\newtheorem{Theorem}{Theorem}
%\numberwithin{Theorem}{chapter}
%\newtheorem{Proposition}{Proposition}
%\newtheorem{Lemma}[Theorem]{Lemma}
%\newtheorem{Corollary}[Theorem]{Corollary}
%\newtheorem{Example}[Theorem]{Example}
%\theoremstyle{definition}
\theoremstyle{definition}
\newtheorem{Remark}[Theorem]{Remark}
\theoremstyle{definition}
\newtheorem{Problem}{Problem}
\theoremstyle{definition}
\newenvironment{parts}{\begin{enumerate}[label=(\alph*)]}{\end{enumerate}}
%tikz	
\tcbset{breakable=true,toprule at break = 0mm,bottomrule at break = 0mm}
\usetikzlibrary{patterns}
\usetikzlibrary{matrix}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
% definitions of number sets
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\allowdisplaybreaks
\begin{document}
	\title{Stochastic Differential Equations}
	\author{Jun Wei Tan}
	\email{jun-wei.tan@stud-mail.uni-wuerzburg.de}
	\affiliation{Julius-Maximilians-Universit\"{a}t W\"{u}rzburg}
	\date{\today}
	\maketitle
	
	{\color{red} My presentation will be on stochastic differential equations. The first question is: What is a stochastic differential equation?
	
	(Write definition)}
	\begin{Definition}
		A stochastic differential equation is a (formal) equation of the form
		\begin{equation}\label{eq:SDEdiff}
			\dv{X_t}{t}=\mu(t, X_t)+\sigma(t, X_t)W_t,
		\end{equation}
		where $W_t$ is white noise. 
	\end{Definition}
	{\color{red}White noise can be understood in the intuitive way --- as a perturbation whose value at all time $t$ is uncorrelated.
	
	Physically, we can intuitively think of white noise as the derivative of Brownian motion
	\[W_t = \dv{B_t}{t}.\]
	However, as we know from the previous presentations, $B_t$ is almost certainly nowhere differentiable. Hence, we cannot take the derivative. Instead, we are to interpret this in a \emph{distributional} sense: (Write definition)}
	\begin{Definition}
		We say that the stochastic process $X_t$ is a \emph{solution} of the SDE \eqref{eq:SDEdiff} if
		\[X_t = X_0+\int_0^t \mu(s, X_s)\dd{s}+ \int_0^t \sigma(s, X_s)\dd{B_s}\]
	\end{Definition}
	{\color{red} This should be reminiscent of the integral form of an ordinary differential equation. Let us look at some solutions.}
	
	The standard method to solve a stochastic differential equation is the Itô formula {\color{red}, which \begin{Theorem}[The 1-Dimensional Itô Formula]
			Suppose $X_t$ is an Itô process. Let $g(t,x)\in C^2([0,\infty)\times \R)$. Then
			\[Y_t=g(t, X_t)\]
			is also an Itô process, and
			\[\dd{Y_t}=\pdv{g}{t}(t, X_t)\dd{t}+\pdv{g}{x}(t, X_t)\dd{X_t}+\frac 12 \pdv[2]{g}{x}(t, X_t)\cdot (\dd{X_t})^2\]
			where $(\dd{X_t})^2$ is computed according to the rules $\dd{t}\cdot \dd{t} = \dd{t}\cdot \dd{B_t}=0$ and $\dd{B_t}\cdot \dd{B_t}=\dd{t}$.
		\end{Theorem}
		where an Itô process is defined as follows
		\begin{Definition}[Itô Process]
			An Itô process is a stochastic process of the form
			\[X_t = X_a +\int_a^t \mu(s)\dd{s} + \int_a^t \sigma(s)\dd{B(s)}\]
		\end{Definition}
	{\color{red} Using this, we can solve some stochastic differential equations by guessing the solutions.}
	
	Let us look at an example:
	\begin{Example}
		A model of a population is given by the stochastic differential equation
		\[\dv{N_t}{t} = r N_t + \alpha W_t N_t.\]
		Here, $r,\alpha$ are constants and $W_t$ is white noise.
	\end{Example}
	{\color{red} This is the well known model for a population growth, where the growth of the population is proportional to the population itself. However, here, we introduce a perturbation that could be due to environmental factors. The size of this perturbation is controlled by the parameter $\alpha$.}
		
	\textcolor{red}{\sout{This is the well known model for a population, except that we have allowed $r$ to vary by a white noise term. The solution in the nonstochastic limit is given by a simple exponential.}} To solve this, we first rewrite the SDE in standard form:
	\[\dd{N_t}=r N_t\dd{t}+\alpha N_t \dd{B_t},\]
	or
	\[\frac{\dd{N_t}}{N_t} = r \dd{t} + \alpha \dd{B_t}.\]
	Inspired by the solution in the deterministic case, we guess $g(t, x)=\ln x$ in Itô's formula, and let $Y_t=g(t, N_t)$. Then, we have
	\[\dd{Y_t}=\frac{\dd{N_t}}{N_t}+\frac 12 \alpha^2 \dd{t}.\]
	Substituting, we have
	\[\dd{Y_t} = \left(r- \frac 12\alpha^2 \right)\dd{t} +\alpha B_t\]
	which integrates easily to yield
	\[N_t = N_0 \exp\left(\left(r - \frac 12 \alpha^2\right)t+\alpha B_t\right).\]
	Clearly, for $\alpha=0$, this reduces to the well known exponential solution. This process is known as \uline{geometric Brownian motion}, which, for example, is a solution to the Black-Scholes equation~\cite{inbook}.
	
	{\color{red} As in the theory of deterministic differential equations, one of the central results is that of existence and uniqueness of solutions. As an ordinary differential equation is a special case of a stochastic differential equation when we use the dirac delta distribution, or formally, the dirac measure, we begin by recalling the basic theorem for an ordinary differential equation, also known as the Picard-Lindelöf theorem: If
	\[\dot{x}= f(t,x)\text{ (write ODE)}\]
	is a differential equation, and $f$ is Lipschitz continuous with respect to $x$, with Lipschitz constant independent of time, then we have a unique solution of the ODE.}
	
	{\color{red} \sout{Now, we turn to the questions of existence and uniqueness. Recall the basic theorem for existence and uniqueness of a deterministic differential equation}}
	\begin{Theorem}[Picard-Lindelöf]
		Let $\dot{x} = f(t,x)$ be a differential equation with $f$ defined on a rectangle $[a,b]\times \R^n$. If $f$ is Lipschitz continuous in $x$, with Lipschitz constant independent of time, and continuous in time, then the differential equation has a unique global solution on $[a,b]$.
	\end{Theorem}
	Note that for uniqueness we do not need the continuity in time; the Lipschitz condition alone suffices. This extends to the stochastic case:
	\begin{Theorem}
		Let $\sigma(t,x)$ and $f(t,x)$ be measurable functions on $[a,b]\times \R$ satisfying the Lipschitz condition in $x$, and $\mathcal{F}$ a filtration such that the Brownian motion is adapted to it. Suppose $\xi$ is an $\mathcal{F}_a$-measurable random variable satisfying $\mathbb{E}[\xi^2]<\infty$. Then the stochastic differential equation
		\[\dv{X_t}{t}=\mu(t, X_t)+\sigma(t, X_t)W_t\]
		has at most one continuous solution on $[a,b]$.
	\end{Theorem}
	\begin{proof}
		We will not go through the proof in detail. Instead, we will talk about the main steps. Assume we have two solutions $X_t$ and $Y_t$. We seek to estimate $Z_t=X_t-Y_t$
		\begin{enumerate}
			\item We estimate the expectation value $\mathbb{E}(Z_t^2)$, using the Lipschitz condition.
			{\color{red}
					\[Z_t = \int_a^t (\sigma(s, X_s) - \sigma (s, Y_s))\dd{B(s)}+\int_a^t (\mu(s, X_s) - \mu(s, Y_s))\dd{s}.\]}
			\item We obtain an integral inequality
			\[
			E(Z_t^2) \le 2K^2 (1+b-a)\int_a^t \mathbb{E}(Z_s^2)\dd{s}
			,\]
			{\color{red} This is a deterministic differential equation in the squared expectation value, and we have seen this in the theory of deterministic differential equations too. The standard method is to apply what is called Gronwall's inequality, which shows that
				\[E(Z_t^2) = 0~\forall t\]}
			\item {\color{red} At this point, it is important to comment about the importance of the condition of continuity in the theorem, which we have not used yet. What we have shown is that for all time $t$, we have a set
				\[\forall t, \exists \Omega_t \text{ s.t. }\mathbb{P}(\Omega_t) = 1, Z_t = 0\text{ on }\Omega_t\]
			This does not suffice --- we need a slightly different condition, that there exists a set $\Omega$, with probability one such that $Z_t$ is 0 on $\Omega$ for \emph{all} time!
			\[\exists \Omega, \mathbb{P}(\Omega) = 1, Z_t=0\text{ on }\Omega \forall t\]
			This follows by the definition of sample path continuity, that
			\[t\mapsto Z_t(\omega)~\forall \omega\]
		}
		 Then, we extend the solution to show that $Z_t$ is $0$ almost surely, using sample path continuity.\qedhere
		\end{enumerate}
	\end{proof}
	The existence theorem is as follows:
	\begin{Theorem}
		The stochastic differential equation \eqref{eq:SDEdiff} has a unique solution with initial condition $\xi$, where $\xi^2$ has finite expectation, $\sigma$ and $\mu$ are Lipschitz in $x$, with Lipschitz constant independent of $t$, and continuous in $t$.
	\end{Theorem}
	\begin{proof}
		The proof follows by Picard Iteration much as it does in the deterministic case. We define $X_0=\xi$ and
		\[
		X_t^{(n+1)}=X_0+\int_0^t b(s, X_s^{(n)})\dd{s}+\int_0^t \sigma(s, X_s^{(n)})\dd{B_s}
		.\] 
		Then, the proof proceeds in two steps. First, we show that this sequence converges.
		{\color{red} The estimate we get will be of the form
		\[
				\mathbb{E}|X_{n+1}(t) - X_n(t)|\le 2B^2(T+1)\int_0^t \mathbb{E}|X^{(n)}_s - X^{(n-1)}_s|^2\dd{s}
		.\]
		This is reminiscent of a geometric sequence, which converges to 0. Using this, we can see that we have uniform convergence on compact intervals. Then, by the Lipschitz continuity, we have $\mu(X^{(n)}) \to \mu(X)$ and $\sigma(X^{(n)})\to \sigma(X)$.
		
		Then, by the dominated convergence theorem, we can take the limit into the integral and show that the limit function $X$ is a solution of the SDE.
		}
		If it does, and converges in a dominated manner, it satisfies the integral equation by the dominated convergence theorem. 
	\end{proof}
	It is a known property of initial value problems that the future solution is not dependent on the past. In particular, we can imagine that we have some initial state $x(0)$ and let it evolve a time $t$ to $x(t)$. {\color{red} Draw graph} Then we can let it evolve further. Alternatively, we can consider an initial value problem that has the value $x(t)$ at time $t$. We expect that these two solutions are identical. In a stochastic differential equation, this ``memory'' property is known as the Markov property. {\color{red} Perhaps it is best to define the Markov property for discrete time differential equations first. A discrete time system is said to have the Markov property if for all time, we have
		\[\mathbb{P}(X_{t+1} \le x | X_t = x_t, \dots, x_0 = x_0) = \mathbb{P}(X_{t+1} \le x | X_t = x_t),\]
		or that the distribution only depends on the timestep just before where we are --- alternatively, where we are going next only depends on where are are now, and not where we were.
		
		In a continuous time process, there is no immediate predecessor, and thus we require the alternative definition} 
	\begin{Definition}
		A stochastic process $X_t$, with $a\le t \le b$, is said to have the \emph{Markov property} if for all sequences $a < t_1 < \dots < t_n < t < b$ and corresponding $x_1, \dots, x_n$, we have
		\[
		\mathbb{P}(X_t\le x|X_{t_1}=x_1, \dots, X_{t_n}=x_n) = \mathbb{P}(X_t\le x|X_{t_n}=x_n)
		.\] 
	\end{Definition}
	As an example, all processes with independent increments have the Markov property. The theorem we seek is thus
	
	\begin{Theorem}
		The solution to \eqref{eq:SDEdiff} is a Markov process.
	\end{Theorem}
	
	The final property that is of interest to us is time translation invariance. For a deterministic differential equation $\dot{x} = f(x)$, we know that the solution exhibits time translation invariance. In the deterministic case, this is quite easy to see, and follows from the fact that $\dv{t}\varphi(t - t_0) = \varphi'(t-t_0)$. {\color{red} Draw graph}
	
	In this case, the relevant property is called the \emph{stationary Markov property}
	\begin{Definition}
		A stochastic process $X$ is called stationary if the moments are time translation invariant:
		\[
		\langle X_{t_1+\tau}X_{t_2+\tau}\dots X_{t_n+\tau}\rangle = \langle X_{t_1}X_{t_2}\dots X_{t_n}\rangle
		\]
		for all $n,\tau$ and $t_1, \dots, t_n$.
	\end{Definition}
	
	Thus, we have our final theorem
	\begin{Theorem}
		Suppose that $\mu(x)$ and $\sigma(x)$ are functions satisfying the Lipschitz condition. Then the solution to
		\begin{equation}\label{eq:SDEdiff2}
			\dv{X_t}{t}=\mu(X_t)+\sigma(X_t)W_t,
		\end{equation}
		is a stationary Markov process.
	\end{Theorem}
	As an example of this, we solve the Langevin equation. {\color{red} The Langevin equation can be understood to be the brownian motion with an extra damping force proportional to the velocity.}
	\begin{Example}
		The Langevin equation is the SDE given by
		\[\dd{X_t} = \mu X_t \dd{t} + \sigma \dd{B_t}.\]
		It has solutions
		\[X_t = e^{\mu t}X_0 + \int_0^t \sigma e^{\mu(t-s)}\dd{B_s}\]
	\end{Example}
	\begin{proof}
		We multiply by the ``integrating factor'' $e^{-\mu t}$ and consider
		\[Y_t = e^{-\mu t}X_t.\]
		By Itô's formula, we have
		\begin{align*}
			\dd{Y_t} &= -\mu e^{-\mu t}X_t \dd{t} + e^{-\mu t}\dd{X_t}\\
			&=  -\mu e^{-\mu t}X_t \dd{t} + e^{-\mu t}(\mu X_t \dd{t} + \sigma \dd{B_t})\\
			&= e^{-\mu t}\sigma \dd{B_t}
		\end{align*}
		implying that
		\[X_t = e^{\mu t}X_0 + \int_0^t \sigma e^{\mu(t-s)}\dd{B_s}.\qedhere\]
	\end{proof}
	Finally, we note that some stochastic processes can be described through density functions. Where such a density function is available, it satisfies the \emph{Fokker-Planck Equation}
	\begin{Theorem}
		The probability density of the solution to Eq. \eqref{eq:SDEdiff} $p(x,t)$ satisfies the equation
		\[\pdv{p(x,t)}{t}=-\pdv{x}[\mu(x,t)p(x,t)]+\pdv[2]{x}[D(x,t)p(x,t)]\]
		where $D(x,t) =\frac{\sigma^2(X_t, t)}{2}$ is the diffusion coefficient.
	\end{Theorem}
\end{document}

