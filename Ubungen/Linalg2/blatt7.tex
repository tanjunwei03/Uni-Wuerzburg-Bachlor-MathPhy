\begin{Problem}
	Beweisen oder Widerlegen Sie:
	\begin{parts}
		\item Es sei $A\in \mathbb{K}^{n\times n}$ und $p\in\mathbb{K}[x]$ ein beliebiges Polynom, dann gilt: Ist $\lambda$ ein Eigenwert von $A$, dann ist $p(\lambda)$ ein Eigenwert von $p(A)$.
		\item Angenommen wir haben in (a) eine Konstellation in der $\lambda$ ein Eigenwert von $A$ und $p(\lambda)$ ein Eigenwert von $p(A)$ ist, dann stimmen jeweils auch die geometrischen Vielfachheiten überein.  
		\item Eine $n\times n$ Matrix mit $n$ paarweise verscheidenen Eigenwerten ist invertierbar.
		\item Im Falle der Intervierbarkeit ist $\lambda$ ein Eigenwert von $A\in \mathbb{K}^{n\times n}$ genau dann, wen $\lambda^{-1}$ ein Eigenwert von $A^{-1}$ ist.
		\item Sind zwei Matrizen $A$ und $B$ ähnlich, dann haben sie dieselben Eigenwert.
		\item Sind zwei Matrizen $A$ und $B$ äquivalent, dann haben sie dieselben Eigenwert.
		\item Sind zwei Matrizen $A$ und $B$ ähnlich so folgt: Ist $\lambda$ ein Eigenwert von $A$ dann ist $\lambda$ ein Eigenwert von $(A + B) / 2$.
	\end{parts}
\end{Problem}
\begin{proof}
	\begin{parts}
	\item Wahr. Sei $p=a_0+a_1x+a_2x^2+\dots + a_n x^n$. 

		Sei $v$ ein Eigenvektor von $A$ mit Eigenwert $\lambda$. Es gilt
		\begin{align*}
			p(A)v=& \left( a_0+a_1A+a_2 A^2+\dots+a_n A^n \right)v\\
			=&a_0v+a_1Av+a_2A^2v+\dots+a_n A^nv\\
			=&a_0v+a_1\lambda v+a_2\lambda^2 v+\dots+a_n\lambda^n v\\
			=&(a_0+a_1\lambda+a_2\lambda^2+\dots+a_n\lambda^n)v\\
			=&p(\lambda)v
		\end{align*}
	\item Wahr. Aus (a) wissen wir, dass die Eigenvektoren sich nicht verändern. Also bezüglich $A$ entscheiden wir uns f\"{u}r eine Basis, deren Dimension die geometrische Vielfachheit ist, dann bleibt die auch eine Basis f\"{u}r das Eigenraum bezüglich das Eigenwert $p(\lambda)$.
	\item Wahr. Es gibt eine Basis von $n$ Eigenvektoren (es ist eine Basis, weil die linear unabhängig sind (Korollar 6.59)). 

		Dann ist $\left\{ \lambda_i v_i|i\in 1,2,\dots,n \right\} $ auch eine Basis, weil Multiplikation durch ein Konstant kann die linear Unabhängigkeit nicht verletzten.
	\item Wahr. Sei $v$ ein Eigenvektor von $A$ mit Eigenwert $\lambda$. Es gilt per Definition
		\[
		Av=\lambda v
		.\] 
		Außerdem gilt
		\[
			Av=A^{-1}A Av=A^{-1}A(\lambda v)=\lambda A^{-1}Av
		,\] 
		also
		\[
			\frac{1}{\lambda}Av=A^{-1}(Av)
		.\] 
		Das heißt, dass $Av$ ein Eigenvektor von $A^{-1}$ mit Eigenwert $\lambda^{-1}$ ist.

		Sei jetzt $v$ ein Eigenvektor von $A^{-1}$ mit Eigenwert $\lambda$. Ähnlich gilt
		\[
			A^{-1}v=A A^{-1}A^{-1}v=A A^{-1}(\lambda v)=\lambda A A^{-1}v
		\]
		und die andere Richtung folgt.
	\item Wahr. Sei $A=Q^{-1}BQ$. Sei außerdem $v$ ein Eigenvektor von $A$ mit Eigenwert $\lambda$. Es gilt $QA=BQ$ und
		\begin{align*}
			QAv=&Q\lambda v=\lambda(Qv)\\
			=&BQv=B(Qv)
		\end{align*}
		also $Qv$ ist ein Eigenvektor von $B$ mit Eigenwert $\lambda$. Wir können die Rollen von $A$ und $B$ vertauschen, um die andere Richtung zu zeigen. 
	\item Falsch.
		\begin{tcolorbox}[title=Definition]
			Seien $A,B\in M_{n\times m}(\mathbb{K})$. Dann heißen $A$ und $B$ äquivalent, falls es $Q\in\text{GL}_n(\mathbb{K})$ und $P\in \text{GL}_m(\mathbb{K})$ gibt, sodass
			\[
			A=QBP
			.\] 
		\end{tcolorbox}
		Sei $A=\text{diag}(4,4),~B=\text{diag}(1,1),~Q=P=\text{diag}(2,2)$. Dann hat $A$ nur den Eigenwert $4$ während $B$ nur den Eigenwert $1$ hat.
	\item Falsch. Sei
		\[
			B=\begin{pmatrix} 1 & 2 \\ 2 & 1 \end{pmatrix},\qquad P=\begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix},\qquad A=P^{-1}BP=\begin{pmatrix} 3 & 6 \\ 0 & 1 \end{pmatrix} 
		.\] 
		Dann hat $B$ die Eigenwerte 3 und -1, aber $(A+B) / 2$ hat characteristisches Polynom $x^2-2x-4$. Durch Einsetzen können wir zeigen, dass weder 3 noch -1 Nullstellen sind, aber die Diskriminante ist $>0$, also wir haben zwei unterschiedliche Nullstellen.

		Das zeigt, dass $B$ bzw. $A$ Eigenwerte hat, die keine Eigenwerte von $(A+ B) / 2$ sind und $(A + B) / 2$ hat Eigenwerte, die keine Eigenwerte von $A$ bzw. $B$ sind.\qedhere
	\end{parts}
\end{proof}
\begin{Problem}
	Es seien $A,B$ in $\mathbb{K}^{n\times n}$ diagonalisierbar und $D_A$, $D_B$ zugehörige Diagonalmatrizen. Zeigen Sie:
	\begin{parts}
	\item Existiert ein $U\in \text{GL}_n(\mathbb{K})$ mit
		\[
			D_A=U^{-1}AU,\qquad D_B=U^{-1}BU
		\]
		so gilt f\"{u}r den Kommutator $[A,B]=0$.
	\item Ist $[A,B]=0$, dann existiert eine geordnete Basis $V=\left\{ v_1,\dots, v_n \right\} $ aus Eigenvektoren von $A$ zu den Eigenwerten $\lambda_1,\dots, \lambda_r$ bezüglich derer gilt
		\[
			_V[B]_V=\begin{pmatrix} B_1 & & &\\ & B_2 & &\\& & \ddots &\\ & & & B_r \end{pmatrix} 
		\]
		mit $B_1\in\mathbb{K}^{d_i\times d_i}$ und $d_i$ die geometrische Vielfachheit von $\lambda_i$ f\"{u}r $i=1,\dots, r$.
	\item Jedes der $B_i$ wie in (b) ist selbst wieder diagonalisierbar f\"{u}r $i=1,\dots, r$.
	\item Ist $[A,B]=0$, so existiert ein $U$ mit
		\[
			D_A=U^{-1}AU,\qquad D_B=U^{-1}BU
		.\] 
	\end{parts}
\end{Problem}
\begin{proof}
	\begin{parts}
	\item Es gilt
		\begin{align*}
			[A,B]=&AB-BA\\
			=&UD_AU^{-1}UD_BU^{-1}-UD_BU^{-1}UD_AU^{-1}\\
			=&UD_AD_BU^{-1}-UD_BD_AU^{-1}\\
			=&UD_AD_BU^{-1}-UD_AD_BU^{-1} & \text{Diagonalmatrizen kommutieren}\\
			=&0
		\end{align*}
	\item Sei $v$ ein Eigenvektor von $A$ mit Eigenwert $\lambda$. Es gilt
		\begin{align*}
			[A,B]v=&0v=0\\
			=&(AB-BA)v\\
			=&ABv=B(\lambda v)\\
			\lambda Bv=&A(Bv)
		\end{align*}
		Dann ist $Bv$ ein Eigenvektor von $A$ mit gleichen Eigenwert. Wir wählen eine geordnete Basis aus Eigenvektoren, so dass alle Eigenvektoren mit gleichen Eigenwerte nebeneinander stehen. 

		Wir haben schon gezeigt, dass $B v$ ein Vektor mit dem gleichen Eigenwert ist, also er liegt noch im Eigenraum. Das heißt, das die nicht (block-)diagonal Terme null sein müssen und das Matrix ist block-diagonal (wobei die Spalten die Wirkung von $B$ auf einem Vektor der Basis bzw. Eigenvektor von $A$ darstellen). Als Darstellung der Wirkung eines Eigenräumes ist es auch klar, dass die Dimension die Dimension des Eigenräumes ist, was per Definition die geometrische Vielfachhheit ist.
	\item Wir betrachten das charakterische Polynom von $B_i$, und bezeichnen es mit $p_i(\lambda)$. Es gilt $p_1(\lambda)p_2(\lambda)\dots p_r(\lambda)=p(\lambda)$, wobei $p(\lambda)$ das charakteristische Polynom f\"{u}r $_V[B]_V$ ist.
		
		Dann ist jede Eigenwert von einem $B_i$ auch ein Eigenwert von $_V[B]_V$, und zu jedem Eigenwert von $B$ gehört einen Eigenvektor. Wir wissen, dass wir aus solche Eigenvektoren eine Basis bilden können (weil $B$ diagonaliserbar ist), also wir können aus eine Teilmenge eine Basis f\"{u}r $B_i$ bilden.
	\item Wir können das Bild und Zielbereich von $B_i$ als einen Eigenraum von $A$ betrachten. Aus (c) wissen wir, dass wir durch ein Basiswechsel $B_i$ diagonalisieren können. Weil das Bild genau ein Eigenraum ist, enthält die Basis nur Eigenvektoren von $A$, also $A$ bleibt diagonal, während $B$ jetzt nach der Basiswechsel diagonal ist. 

		Wir haben dann $A$ und $B$ gleichzeitig diagonalisiert. Sei $U$ das Matrix mit Vektoren von die Basis als Spalten. Dann gilt
\[
	D_A=U^{-1}AU\qquad D_B=U^{-1}BU
.\qedhere\] 
	\end{parts}
\end{proof}
\begin{Problem}
	Es sei
	\[
		A=\begin{pmatrix} 1 & 0 & 0 & 0 \\ 1 & 1 & -1 & 1 \\ 2 & -1 & 1 & 1\\3 & -1 & -1 & 3 \end{pmatrix} 
	\]
	ein reelle Matrix.
	\begin{parts}
	\item Bestimmen Sie das charakteristische Polynom von $A$.
	\item Bestimmen Sie alle Eigenwerte und dazugehörige Eigenräume.
	\item Im Falle der Diagonalisierbarkeit, bestimmen Sie explizit die Projektoren $P_1,\dots, P_r$ auf die $r$-vielen Eigenräume, sodass gilt
	\[
		A=\sum_{i=1}^r \lambda_i P_i
	.\] 
	\end{parts}
\end{Problem}
\begin{proof}
	\begin{parts}
	\item 
		\begin{align*}
			p(\lambda)=&\text{det}(A-\lambda I)\\
			=& \begin{vmatrix}
				1 - \lambda & 0 & 0 & 0\\1 & 1-\lambda & -1 & 1\\2 & -1 & 1-\lambda & 1\\3 & -1 & -1 & 3-\lambda
			\end{vmatrix}\\
				=&(1-\lambda)\begin{vmatrix}
					1-\lambda & -1 & 1 \\ -1 & 1-\lambda & 1 \\ -1 & -1 & 3-\lambda
				\end{vmatrix}\\
					=&(1-\lambda)\left[ (1-\lambda)((1-\lambda)(3-\lambda)+1)+(\lambda-3+1)+(2+1-\lambda) \right] \\
					=&(1-\lambda)\left[ (1-\lambda)(3+\lambda^2-4\lambda+1)+\lambda-2+2-\lambda \right] \\
					=&(1-\lambda)^2(3+\lambda^2-4\lambda+1)\\
					=&(1-\lambda)^2(\lambda^2-4\lambda+4)\\
					=&(1-\lambda)^2(\lambda-2)^2
		\end{align*}
	\item Die Eigenwerte sind $1$ und $2$. Es gilt
		\[
			A-1=\begin{pmatrix} 0 & 0 & 0 & 0 \\ 1 & 0 & -1 & 1 \\ 2 & -1 & 0 & 1 \\ 3 & -1 & -1 & 2 \end{pmatrix} 
		.\] 
		Eine Basis f\"{u}r den Eigenraum bzw. Kern von $A-1$ ergibt sich sofort:
		\[
			ER_{1}=\text{span}\left(\left\{ \begin{pmatrix} 1 \\ 2 \\ 1 \\ 0 \end{pmatrix} , \begin{pmatrix} 1 \\ 1 \\ 0 \\ -1 \end{pmatrix}  \right\}\right) 
		.\] 
		Weil wir schon $2$ Vektoren gefunden haben, und die algebraische Vielfachheit $2$ ist, haben wir den ganzen Eigenraum gefunden. Es gilt auch
		\[
			A-2=\begin{pmatrix} -1 & 0 & 0 & 0 \\ 1 & -1 & -1 & 1 \\ 2 & -1 & -1 & 1 \\ 3 & -1 & -1 & 1 \end{pmatrix} 
		.\] 
		Eine Basis ergibt sich sofort:
		\[
			ER_2=\text{span}\left(\left\{ \begin{pmatrix} 0 \\ 1 \\ 0 \\ 1 \end{pmatrix} , \begin{pmatrix} 0 \\ 0 \\ 1 \\ 1 \end{pmatrix}  \right\}\right) 
		.\] 
	\item 
		Wir schreiben eine neue Basis von Eigenvektoren:
		\[
			ER_1=\text{span}\left( \left\{\frac{1}{\sqrt{6} } \begin{pmatrix}1 \\ 2 \\ 1 \\ 0  \end{pmatrix}, \frac{1}{\sqrt{6} }\begin{pmatrix} 1 \\ 0 \\ -1 \\ -2 \end{pmatrix}   \right\}  \right) 
		\]
		und
		\[
			ER_2=\text{span}\left( \left\{ \frac{1}{\sqrt{6} }\begin{pmatrix} 0 \\ 1 \\ -2 \\ 1 \end{pmatrix} , \frac{1}{\sqrt{6} }\begin{pmatrix} 2 \\ -1 \\ 0 \\ 1 \end{pmatrix}  \right\}  \right) 
		.\] 
		Dann sind die Projektoren
		\begin{align*}
			P_1'=&\frac{1}{6}\begin{pmatrix} 1 \\ 2 \\ 1 \\ 0 \end{pmatrix} \begin{pmatrix} 1 & 2 & 1 & 0 \end{pmatrix} +\frac{1}{6}\begin{pmatrix} 1 \\ 0 \\ -1 \\ -2 \end{pmatrix} \begin{pmatrix} 1 & 0 & -1 & -2 \end{pmatrix} \\
		=&\frac{1}{3}\left(
\begin{array}{cccc}
 1 & 1 & 0 & -1 \\
 1 & 2 & 1 & 0 \\
 0 & 1 & 1 & 1 \\
 -1 & 0 & 1 & 2 \\
\end{array}
\right) \\
			P_2'=&\frac{1}{6}\begin{pmatrix}  0 \\ 1 \\ -2 \\ 1 \end{pmatrix} \begin{pmatrix} 0 & 1 & -2 & 1 \end{pmatrix} +\frac{1}{6}\begin{pmatrix} 2 \\ -1 \\ 0 \\ 1 \end{pmatrix} \begin{pmatrix} 2 & -1 & 0 & 1 \end{pmatrix}\\
			=&\frac{1}{3}\left(
\begin{array}{cccc}
 2 & -1 & 0 & 1 \\
 -1 & 1 & -1 & 0 \\
 0 & -1 & 2 & -1 \\
 1 & 0 & -1 & 1 \\
\end{array}
\right) 
	\end{align*}
	Dann ist $P_1',P_2'$ eine Zerlegung der Eins. Die gewünschte Projektoren sind
	\begin{gather*}
		P_1=AP_1'=\frac{1}{3}\left(
\begin{array}{cccc}
 1 & 1 & 0 & -1 \\
 1 & 2 & 1 & 0 \\
 0 & 1 & 1 & 1 \\
 -1 & 0 & 1 & 2 \\
\end{array}
\right)\\
P_2=AP_2'=\frac{1}{3}\left(
\begin{array}{cccc}
 2 & -1 & 0 & 1 \\
 2 & 1 & -4 & 3 \\
 6 & -4 & 2 & 2 \\
 10 & -3 & -4 & 7 \\
\end{array}
\right) 
	\end{gather*}
	und es gilt $A=P_1+P_2$.\qedhere
	\end{parts}
\end{proof}
